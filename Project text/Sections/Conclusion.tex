\section{Conclusion}



% Retraction comparison
Regarding the retraction experiment, in section \ref{sec:retraction_comparison}, apart from reaffirming the dominance of the Cayley retraction over the Riemannian geodesic in terms of computational efficiency (as observed in both \cite[p.~8]{JensenZimmermann2024} and \cite[p.~26]{BendokatZimmermann2021}), we also found that the pseudo-Riemannian geodesic performed comparably or better than the Cayley retraction. It is unexpected that the pseudo-Riemannian geodesic performed as well as it did seeing as in \cite[p.~28]{BendokatZimmermann2021} it was excluded from a similar test to the one presented in this report. This was because it seemed to do rather unimpressively in an earlier test Bendokat and Zimmermann performed. Given that the pseudo-Riemannian geodesic was seemingly as accurate as the Riemannian geodesic, in addition to being as fast as the Cayley transformation, further investigation into the pseudo-Riemannian geodesic is warranted.

% Nearest symplectic element
The results for the experiments presented are in line with the experiment done by Jensen and Zimmermann \cite[Tbl.~41]{JensenZimmermann2024}. We observed for $n=100$, and $k=\left\{ 5,10,20 \right\}$ that GD was superior in runtime, with indication that this would not be the case for larger problems. This is indeed what Jensen and Zimmermann observes for $n=1000$, and $k=\left\{ 10,50,100 \right\}$, with GD slightly beating the others for $k=10$, and ultimately TR-2 surpassing GD in terms of speed for $k=\left\{ 50,100 \right\}$. Worth noting is that some of the superior numerical accuracy by TR-1 and TR-2 pointed out by Jensen and Zimmermann, which they conclude is purely due to the fact that TR-1 and TR-2 make use of second order information, could be misinterpreted. As we commented on in section \ref{sec:NSM_2nd_order}, we can see in Figure \ref{fig:nearest_symplectic_matrix_2nd_order} that TR-1 and TR-2 tend to overshoot the convergence condition of $\lvert \lvert \operatorname{grad}f(p) \rvert \rvert_{p}\leq10^{-6}$, while GD does not. This effect has the potential to muddy the waters when comparing TR-1 and TR-2 to GD. Despite this concern, we do observe that for larger systems, i.e. larger $k$, this effect became smaller. It is therefore possible that for the larger system Jensen and Zimmermann tested, the overshooting effect was negligible.

% Symplectic decomposition
The code for the nearest symplectic element experiment and the proper symplectic decomposition is nearly identical - but for the optimization problem itself. Despite this, in the first experiment all algorithms converge, while in the other none of them do. As Jensen and Zimmermann published their code on github, we were able to compare their MATLAB code with our Julia code. After generating matrices for $p$, $s$, and $X$ in Julia, we inserted these into the MATLAB code. Through this we were able to verify that $f(p)$, $\nabla f(p)$, and $\nabla^{2}f(p)[X]$ output equivalent matrices in both frameworks. The fact that all three are failing to converge could be because $\operatorname{grad}f(p)$ is not correct. However, Manopt.jl's built-in functions "checkgradient" as well as "checkhessian" shows that both the Riemannian gradient, as well as the Hessian, looks correct. In fact, as MATLAB's manopt also has a "checkgradient"-function, inserting the same $p$ and $X$ as in Julia gives almost the exact same result. All of this debugging leads us to conclude that either we were very unlucky with our starting point or $s$, or there is some problem with the rest of the code that is not of consequence in the nearest symplectic element experiment. Of the two alternatives the second one seems more likely. As the implementation of GD and TR used in our experiments were the ones already implemented in manopt.jl, there might be some additional condition that one needs to change for them to be comparable to the implementations in MATLAB. Since this problem has been rigorously narrowed down in our code, further investigations into solutions may be warranted.

Jensen and Zimmermann chose to leave out the Riemannian BFGS method from their experiments \cite[p.~11]{JensenZimmermann2024}. They did this because they found it to not be competitive to the other methods they used. Despite this it could be interesting to try to validate these findings using \text{Manopt.jl} and/or on problems expected to be better suited to the Riemannian BFGS method.