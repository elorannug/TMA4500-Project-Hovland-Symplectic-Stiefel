\newpage
\section{Conclusion}\label{sec:Conclusion}
In this report we presented the right-invariant framework on the symplectic Stiefel manifold. Through this framework we presented the Riemannian gradient descent algorithm (GD) and the Riemannian trust-region method using the exact Riemannian Hessian (TR-1) and the approximate Riemannian Hessian (TR-2). We used GD to analyze the performance of the Cayley retraction, the pseudo-Riemannian geodesic retraction, and the Riemannian geodesic retraction on the problem of finding the nearest symplectic matrix. Lastly we used the same problem, as well as the proper symplectic decomposition problem, to compare the three algorithms. 

% Retraction comparison
The retraction experiment, in section \ref{sec:retraction_comparison}, apart from reaffirming the dominance of the Cayley retraction over the Riemannian geodesic in terms of computational efficiency (as observed in both \cite[p.~8]{JensenZimmermann2024} and \cite[p.~26]{BendokatZimmermann2021}), we also found that the pseudo-Riemannian geodesic performed comparably or better than the Cayley retraction. It is unexpected that the pseudo-Riemannian geodesic performed as well as it did, seeing as in \cite[p.~28]{BendokatZimmermann2021} it was excluded from a similar test to the one presented in this report. This was because it seemed to do rather unimpressively in an earlier test Bendokat and Zimmermann performed. Given that the pseudo-Riemannian geodesic was seemingly as accurate as the Riemannian geodesic, in addition to being as fast as the Cayley transformation, further investigation into the pseudo-Riemannian geodesic is warranted. 

% Nearest symplectic element
Regarding using the nearest symplectic matrix problem to compare GD, TR-1, and TR-2, the results for the experiments presented in Section \ref{sec:NSM_2nd_order} are mostly in line with the experiment done by Jensen and Zimmermann \cite[Tbl.~4.1]{JensenZimmermann2024}. We observed on $\mathrm{SpSt}(2n, 2k)$ for $n=100$, and $k=5$ that GD was superior in terms of runtime, while on $k=\left\{ 10,20 \right\}$ TR-2 took the lead. Strangely this is mostly in line with what Jensen and Zimmermann observed. They observed that for $n=1000$, and $k=\left\{ 10,50,100 \right\}$, GD barely beat the others for $k=10$, with TR-2 surpassing GD in terms of speed for $k=\left\{ 50,100 \right\}$. It is strange that the results are so similar, seeing as the size of the system is so different. One plausible explanation of the similarity in convergence behavior is that the relative size of $n$ and $k$ could play a significant role in the performance of the algorithms. Actually running the experiments for $n=1000$, and $k=\left\{ 10,50,100 \right\}$ through our implementation could provide more insight into this. It should be noted that Jensen and Zimmermann used a more costly retraction \cite[Fig.~1]{JensenZimmermann2024} than what we used. Despite this the results for GD we observed are not in conflict with other experiments, as in \cite[Tbl.~1]{BendokatZimmermann2021}. It is also worth noting that around iteration $15$ we see that for all three runs in Figure~\ref{fig:nearest_symplectic_matrix_2nd_order}, GD starts to struggle to keep up with TR. Therefore, if speed is of more importance than accuracy, the number of cases where GD is superior to TR will probably be higher. 

Another point worth noting is that the superior numerical accuracy by TR-1 and TR-2 pointed out by Jensen and Zimmermann, which they conclude is purely due to the fact that TR-1 and TR-2 make use of second order information, could be misinterpreted. As we commented on in Section~\ref{sec:NSM_2nd_order}, we can see in Figure~\ref{fig:nearest_symplectic_matrix_2nd_order} that TR-1 and TR-2 tend to overshoot the convergence condition of $\lvert \lvert \operatorname{grad}f(p) \rvert \rvert_{p}\leq10^{-6}$, while GD does not. This effect has the potential to muddy the waters when comparing accuracies of TR-1 and TR-2 to GD. Despite this concern, we do observe that for larger systems, i.e. larger $k$, this effect became smaller. It is therefore possible that for the larger system Jensen and Zimmermann tested, the overshooting effect was negligible.

% Symplectic decomposition
For the problem of performing a proper symplectic decomposition using GD, TR-1, and TR-2, as done in Section~\ref{sec:symplectic_decomposition}, the experiment yielded mixed results compared to the experiment done by Jensen and Zimmermann \cite[Tbl.~4.4]{JensenZimmermann2024}. Regarding TR-1 and TR-2, they seem to share a comparable difference in runtime between each other as they did in Jensen and Zimmermann. The actual pattern of convergence for TR also aligns with the nearest symplectic element problem, which aligns with what is expected in theory. However, there are some discrepancies which we will now describe. 

The biggest discrepancy between our results and the results of Jensen and Zimmermann \cite[Tbl.~4.4]{JensenZimmermann2024} is the performance of GD. While GD had no issue converging within $1000$ iterations in the experiment by Jensen and Zimmermann, even though their system was larger than ours, GD in our experiments failed to converge for all presented values of $k$. From Figure~\ref{fig:symplectic_decomposition}, it appears that the way GD failed to converge was through the step size becoming so small that the algorithm would not converge within a reasonable amount of iterations. This leads us to another discrepancy within our implementation of GD compared to Jensen and Zimmermann. In our implementation of GD the step size is determined by the Armijo condition, while Jensen and Zimmermann uses the Barzilaiâ€“Borwein (BB) method. Since the most likely way GD failed to converge was through the step size becoming too small too fast, the most likely way to fix this issue is to change the step size method to the BB method. However, as this explanation was inferred, further analysis as to why GD failed to converge is warranted.

% Both
An interesting discrepancy between our experiments and Jensen and Zimmermann, which appears in both nearest symplectic element- and the symplectic decomposition problem, is the inferior runtime performance of TR-2 for their respectively lowest value of $k$. This is in contrast to the results of Jensen and Zimmermann, where TR-2 was superior to TR-1 for all three values of $k$. These observations could mean that, for small systems, solving the subproblem \eqref{eq:projection_problem} to find the projection is not worth the computational cost. It could also mean that this method of finding the projection is not as accurate for smaller systems. Implementing the analytical projection of the gradient, as defined in \cite[Lem.~2.3]{JensenZimmermann2024}, and comparing it to the optimization problem \eqref{eq:projection_problem} could therefore be an interesting experiment. 

% Pc issues
It should be noted that since all of the experiments were performed on a laptop, there is a high degree of uncertainty in all of the timed runs. This is because, like most laptops, when they heat up above a certain temperature, the processor will throttle down to prevent overheating. This results in the operations taking longer time, and the time comparison between different runs becomes less reliable. Running the tests on a setup with a more stable temperature would likely produce more reliable results. 

