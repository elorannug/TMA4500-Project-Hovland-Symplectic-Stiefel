\section{Conclusion}\label{sec:Conclusion}
In this report we presented the right-invariant framework on the symplectic Stiefel manifold. Through this framework we presented the Riemannian gradient descent algorithm (GD) and the Riemannian trust-region method using the exact Riemannian Hessian (TR-1) and the approximate Riemannian Hessian (TR-2). We used GD to analyze the performance of the Cayley retraction, the pseudo-Riemannian geodesic retraction, and the Riemannian geodesic retraction on the problem of finding the nearest symplectic matrix. Lastly we used the same problem, as well as the proper symplectic decomposition problem, to compare the three algorithms. 

% Retraction comparison
Regarding the retraction experiment, in section \ref{sec:retraction_comparison}, apart from reaffirming the dominance of the Cayley retraction over the Riemannian geodesic in terms of computational efficiency (as observed in both \cite[p.~8]{JensenZimmermann2024} and \cite[p.~26]{BendokatZimmermann2021}), we also found that the pseudo-Riemannian geodesic performed comparably or better than the Cayley retraction. It is unexpected that the pseudo-Riemannian geodesic performed as well as it did seeing as in \cite[p.~28]{BendokatZimmermann2021} it was excluded from a similar test to the one presented in this report. This was because it seemed to do rather unimpressively in an earlier test Bendokat and Zimmermann performed. Given that the pseudo-Riemannian geodesic was seemingly as accurate as the Riemannian geodesic, in addition to being as fast as the Cayley transformation, further investigation into the pseudo-Riemannian geodesic is warranted. 

% Nearest symplectic element
Regarding using the nearest symplectic matrix problem to compare GD, TR-1, and TR-2, the results for the experiments presented in Section \ref{sec:NSM_2nd_order} are in line with the experiment done by Jensen and Zimmermann \cite[Tbl.~4.1]{JensenZimmermann2024}. We observed on $\mathrm{SpSt}(2n, 2k)$ for $n=100$, and $k=\left\{ 5,10,20 \right\}$ that GD was superior in terms of runtime, with indication that this might not be the case for larger problems. This is indeed what Jensen and Zimmermann observe for $n=1000$, and $k=\left\{ 10,50,100 \right\}$, with GD slightly beating the others for $k=10$, and ultimately TR-2 surpassing GD in terms of speed for $k=\left\{ 50,100 \right\}$. It should be noted that Jensen and Zimmermann used a more costly retraction \cite[Fig.~1]{JensenZimmermann2024} than what we used. Despite this the results for GD we observed are  not in conflict with other experiments either like in \cite[Tbl.~1]{BendokatZimmermann2021}. Another point worth noting is that the superior numerical accuracy by TR-1 and TR-2 pointed out by Jensen and Zimmermann, which they conclude is purely due to the fact that TR-1 and TR-2 make use of second order information, could be misinterpreted. As we commented on in section \ref{sec:NSM_2nd_order}, we can see in Figure~\ref{fig:nearest_symplectic_matrix_2nd_order} that TR-1 and TR-2 tend to overshoot the convergence condition of $\lvert \lvert \operatorname{grad}f(p) \rvert \rvert_{p}\leq10^{-6}$, while GD does not. This effect has the potential to muddy the waters when comparing accuracies of TR-1 and TR-2 to GD. Despite this concern, we do observe that for larger systems, i.e. larger $k$, this effect became smaller. It is therefore possible that for the larger system Jensen and Zimmermann tested, the overshooting effect was negligible.

% Symplectic decomposition
For the problem of performing a proper symplectic decomposition using GD, TR-1 and TR-2, as done in Section \ref{sec:symplectic_decomposition}, the code for the nearest symplectic element experiment and the proper symplectic decomposition is nearly identical - but for the optimization problem itself. Despite this, while in the nearest symplectic matrix problem all algorithms converge, none of them do in this experiment. Since Jensen and Zimmermann published their code on github \cite[p.~15]{JensenZimmermann2024}, we were able to compare their MATLAB code with our Julia code. After generating matrices for $p$, $s$, and $X$ in Julia, we inserted these into the MATLAB code. Through this we were able to verify that $f(p)$, $\nabla f(p)$, and $\nabla^{2}f(p)[X]$ output equivalent matrices in both frameworks. The fact that all three are failing to converge could be because $\operatorname{grad}f(p)$ is not correct. However, Manopt.jl's built-in functions "checkgradient" as well as "checkhessian" shows that both the Riemannian gradient, as well as the Hessian, look correct. In fact, as MATLAB's manopt also has a "checkgradient"-function, inserting the same $p$ and $X$ as in Julia gives almost the exact same result. These debugging results lead us to conclude that either we were unlucky with our starting point or $s$, or there is some problem with the rest of the code that is not of consequence in the nearest symplectic element experiment. Of the two alternatives the second one seems more likely. As the implementation of GD and TR used in our experiments were the ones already implemented in manopt.jl, there might be some additional condition that one needs to change for them to be comparable to the implementations in MATLAB. Since this problem has been rigorously narrowed down in our code, further investigations into solutions may be warranted.

% Pc issues
It should be noted that since the tests were performed on a laptop, there is a high degree of uncertainty in all of the timed runs. This is because, like most laptops, when they heat up above a certain temperature, the processor will throttle down to prevent overheating. This results in the operations taking longer time, and the comparison between different runs becomes less reliable. Running the tests on a setup with a more stable temperature would likely produce more reliable results. 

